{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":24286,"databundleVersionId":1878097,"sourceType":"competition"},{"sourceId":170393555,"sourceType":"kernelVersion"},{"sourceId":170414881,"sourceType":"kernelVersion"},{"sourceId":25836,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":21750},{"sourceId":25851,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":21762}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk\n! pip install timm==0.6.7\n!pip install transformers\n!pip install opencv-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T08:54:18.340111Z","iopub.execute_input":"2024-04-05T08:54:18.340441Z","iopub.status.idle":"2024-04-05T08:55:07.399351Z","shell.execute_reply.started":"2024-04-05T08:54:18.340392Z","shell.execute_reply":"2024-04-05T08:55:07.398082Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: timm==0.6.7 in /opt/conda/lib/python3.10/site-packages (0.6.7)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.10/site-packages (from timm==0.6.7) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm==0.6.7) (0.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4->timm==0.6.7) (2024.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm==0.6.7) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->timm==0.6.7) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm==0.6.7) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4->timm==0.6.7) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm==0.6.7) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm==0.6.7) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm==0.6.7) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->timm==0.6.7) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4->timm==0.6.7) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nimport os\nimport gc\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler, AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n                                      ReduceLROnPlateau)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport albumentations as A \nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport transformers\nfrom transformers import AutoModel, AutoTokenizer\nimport timm\n# albumentations for augs\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:07.405671Z","iopub.execute_input":"2024-04-05T08:55:07.405957Z","iopub.status.idle":"2024-04-05T08:55:12.803963Z","shell.execute_reply.started":"2024-04-05T08:55:07.405926Z","shell.execute_reply":"2024-04-05T08:55:12.802892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"config = {\n    'learning_rate':0.01,\n    'train_batch_size':12,\n    'valid_batch_size':12,\n    'accumulation_step':4,\n    'epochs':15,\n    'nfolds':5,\n    'seed':42,\n    \n    's':30.0,\n    'm':0.5,\n    'ls_eps':0.0,\n    'easy_margin':False,\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:03:05.685811Z","iopub.execute_input":"2024-04-05T09:03:05.686701Z","iopub.status.idle":"2024-04-05T09:03:05.691712Z","shell.execute_reply.started":"2024-04-05T09:03:05.686665Z","shell.execute_reply":"2024-04-05T09:03:05.690788Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = 'bert-base-cased'\n# backbone = AutoModel.from_pretrained(MODEL_PATH)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\ntokenizer.save_pretrained('bert_tokenizer')\n\n# model.save_pretrained('bert_model')\nbackbone = AutoModel.from_pretrained(\"bert-base-cased\")\nbert_config = backbone.config\nbert_config.add_cross_attention = True\nbert_config.is_decoder = True\nbackbone = AutoModel.from_pretrained(\"bert-base-cased\", config=bert_config)\n\nclass Model(nn.Module):\n    def __init__(self,backbone):\n        super(Model,self).__init__()\n        self.backbone = backbone\n        self.in_features = self.backbone.pooler.dense.in_features\n        self.dropout = nn.Dropout(0.2)\n        self.final = ArcMarginProduct(self.in_features, 11014,\n                                      s=config['s'], m=config['m'],\n                                      easy_margin=config['easy_margin'], \n                                      ls_eps=config['ls_eps'])\n    \n    def forward(self,x):\n        output = self.backbone(**x)\n        x = output['last_hidden_state'][:,0,:]\n        x = self.dropout(x)\n        x = self.final(x)\n        return x  \nbert_model = Model(backbone)\nbert_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:04:30.498437Z","iopub.execute_input":"2024-04-05T09:04:30.499185Z","iopub.status.idle":"2024-04-05T09:04:31.672916Z","shell.execute_reply.started":"2024-04-05T09:04:30.499153Z","shell.execute_reply":"2024-04-05T09:04:31.671990Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Some weights of BertModel were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Model(\n  (backbone): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (crossattention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.2, inplace=False)\n  (final): ArcMarginProduct()\n)"},"metadata":{}}]},{"cell_type":"code","source":"config = {\n    'learning_rate':0.01,\n    'train_batch_size':12,\n    'valid_batch_size':12,\n    'accumulation_step':4,\n    'epochs':15,\n    'nfolds':5,\n    'seed':42,\n    \n    's':30.0,\n    'm':0.5,\n    'ls_eps':0.0,\n    'easy_margin':False,\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:04:31.674571Z","iopub.execute_input":"2024-04-05T09:04:31.674860Z","iopub.status.idle":"2024-04-05T09:04:31.679749Z","shell.execute_reply.started":"2024-04-05T09:04:31.674834Z","shell.execute_reply":"2024-04-05T09:04:31.678907Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps  \n        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input):\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight)).to('cuda')\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2)).to('cuda')\n        phi = (cosine * self.cos_m - sine * self.sin_m).to('cuda')\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = torch.zeros(cosine.size(), device='cuda')\n#         one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.300560Z","iopub.execute_input":"2024-04-05T08:55:14.300881Z","iopub.status.idle":"2024-04-05T08:55:14.312386Z","shell.execute_reply.started":"2024-04-05T08:55:14.300843Z","shell.execute_reply":"2024-04-05T08:55:14.311469Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,backbone):\n        super(Model,self).__init__()\n        self.backbone = backbone\n        self.in_features = self.backbone.pooler.dense.in_features\n        self.dropout = nn.Dropout(0.2)\n        self.final = ArcMarginProduct(self.in_features, 11014,\n                                      s=config['s'], m=config['m'],\n                                      easy_margin=config['easy_margin'], \n                                      ls_eps=config['ls_eps'])\n    \n    def forward(self,x,label):\n        output = self.backbone(**x)\n        x = output['last_hidden_state'][:,0,:]\n        x = self.dropout(x)\n        x = self.final(x,label)\n        return x  ","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.313677Z","iopub.execute_input":"2024-04-05T08:55:14.314007Z","iopub.status.idle":"2024-04-05T08:55:14.325187Z","shell.execute_reply.started":"2024-04-05T08:55:14.313974Z","shell.execute_reply":"2024-04-05T08:55:14.324267Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device=torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.326314Z","iopub.execute_input":"2024-04-05T08:55:14.326680Z","iopub.status.idle":"2024-04-05T08:55:14.365164Z","shell.execute_reply.started":"2024-04-05T08:55:14.326654Z","shell.execute_reply":"2024-04-05T08:55:14.364339Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"BEST_BERT_MODEL_PATH = \"../input/bert/pytorch/bert/1/bert.bin\"\n# Defining Model\nbert_model = Model(backbone)\nbert_model.load_state_dict(torch.load(BEST_BERT_MODEL_PATH, map_location=device),  strict=False)\nMODEL_PATH = 'bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n# tokenizer.save_pretrained('bert_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:56:00.746246Z","iopub.execute_input":"2024-04-05T08:56:00.746653Z","iopub.status.idle":"2024-04-05T08:56:01.513667Z","shell.execute_reply.started":"2024-04-05T08:56:00.746621Z","shell.execute_reply":"2024-04-05T08:56:01.512803Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class EfficientNet(nn.Module):\n\n  def __init__(self,\n                n_classes,\n                model_name='efficientnet_b0',\n                use_fc=False,\n                fc_dim=512,\n                dropout=0.0,\n                loss_module='softmax',\n                s=30.0,\n                margin=0.50,\n                ls_eps=0.0,\n                theta_zero=0.785,\n                pretrained=True):\n      \"\"\"\n      :param n_classes:\n      :param model_name: name of model from pretrainedmodels\n          e.g. resnet50, resnext101_32x4d, pnasnet5large\n      :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n      :param loss_module: One of ('arcface', 'cosface', 'softmax')\n      \"\"\"\n      super(EfficientNet, self).__init__()\n      print('Building Model Backbone for {} model'.format(model_name))\n\n      self.backbone = timm.create_model(model_name, pretrained=pretrained)\n      final_in_features = self.backbone.classifier.in_features\n\n      self.backbone.classifier = nn.Identity()\n      self.backbone.global_pool = nn.Identity()\n\n      self.pooling =  nn.AdaptiveAvgPool2d(1)\n\n      self.use_fc = use_fc\n      if use_fc:\n          self.dropout = nn.Dropout(p=dropout)\n          self.fc = nn.Linear(final_in_features, fc_dim)\n          self.bn = nn.BatchNorm1d(fc_dim)\n          self._init_params()\n          final_in_features = fc_dim\n\n      self.loss_module = loss_module\n#       if loss_module == 'arcface':\n      self.final = ArcMarginProduct(final_in_features, n_classes,\n                                    s=s, m=margin, easy_margin=False, ls_eps=ls_eps)\n#       elif loss_module == 'cosface':\n#           self.final = AddMarginProduct(final_in_features, n_classes, s=s, m=margin)\n#       elif loss_module == 'adacos':\n#           self.final = AdaCos(final_in_features, n_classes, m=margin, theta_zero=theta_zero)\n#       else:\n#           self.final = nn.Linear(final_in_features, n_classes)\n\n  def _init_params(self):\n      nn.init.xavier_normal_(self.fc.weight)\n      nn.init.constant_(self.fc.bias, 0)\n      nn.init.constant_(self.bn.weight, 1)\n      nn.init.constant_(self.bn.bias, 0)\n\n  def forward(self, x):\n      feature = self.extract_feat(x)\n      logits = self.final(feature)\n      return logits\n\n  def extract_feat(self, x):\n      batch_size = x.shape[0]\n      x = self.backbone(x)\n      x = self.pooling(x).view(batch_size, -1)\n\n      if self.use_fc:\n          x = self.dropout(x)\n          x = self.fc(x)\n          x = self.bn(x)\n\n      return x","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.599244Z","iopub.execute_input":"2024-04-05T08:55:14.599573Z","iopub.status.idle":"2024-04-05T08:55:14.612632Z","shell.execute_reply.started":"2024-04-05T08:55:14.599546Z","shell.execute_reply":"2024-04-05T08:55:14.611644Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"loss_module = 'arcface'\n\nmodel_params = {\n    'n_classes':11014,\n    'model_name':'efficientnet_b3',\n    'use_fc':False,\n    'fc_dim':512,\n    'dropout':0.0,\n    'loss_module':loss_module,\n    's':30.0,\n    'margin':0.50,\n    'ls_eps':0.0,\n    'theta_zero':0.785,\n    'pretrained':True\n}\n\nDIM = (512,512)\n\nNUM_WORKERS = 4\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 5\nSEED = 42\n#LR = 3e-4\n\n\n################################################# MODEL ####################################################################\n\nmodel_name = 'efficientnet_b3' #efficientnet_b0-b7\n\n################################################ Metric Loss and its params #######################################################\nloss_module = 'arcface' #'cosface' #'adacos'\ns = 30.0\nm = 0.5\nls_eps = 0.0\neasy_margin = False\n\n\n\nscheduler_params = {\n        \"lr_start\": 1e-5,\n        \"lr_max\": 1e-5 * TRAIN_BATCH_SIZE,\n        \"lr_min\": 1e-6,\n        \"lr_ramp_ep\": 5,\n        \"lr_sus_ep\": 0,\n        \"lr_decay\": 0.8,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.614041Z","iopub.execute_input":"2024-04-05T08:55:14.614523Z","iopub.status.idle":"2024-04-05T08:55:14.625732Z","shell.execute_reply.started":"2024-04-05T08:55:14.614485Z","shell.execute_reply":"2024-04-05T08:55:14.624746Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/shopee-product-matching/train.csv')\ndata['filepath'] = data['image'].apply(lambda x: os.path.join('../input/shopee-product-matching', 'train_images', x))\nencoder = LabelEncoder()\ndata['label_group'] = encoder.fit_transform(data['label_group'])","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.626904Z","iopub.execute_input":"2024-04-05T08:55:14.627269Z","iopub.status.idle":"2024-04-05T08:55:14.841970Z","shell.execute_reply.started":"2024-04-05T08:55:14.627232Z","shell.execute_reply":"2024-04-05T08:55:14.840912Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data = data.head(2000)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.843326Z","iopub.execute_input":"2024-04-05T08:55:14.843657Z","iopub.status.idle":"2024-04-05T08:55:14.848551Z","shell.execute_reply.started":"2024-04-05T08:55:14.843627Z","shell.execute_reply":"2024-04-05T08:55:14.847448Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class EfficientNetDataset(Dataset):\n  def __init__(self, csv, transforms=None):\n\n      self.csv = csv.reset_index()\n      self.augmentations = transforms\n\n  def __len__(self):\n      return self.csv.shape[0]\n\n  def __getitem__(self, index):\n      row = self.csv.iloc[index]\n\n      image = cv2.imread(row.filepath)\n      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n      if self.augmentations:\n          augmented = self.augmentations(image=image)\n          image = augmented['image']\n\n\n      return image","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.852484Z","iopub.execute_input":"2024-04-05T08:55:14.852877Z","iopub.status.idle":"2024-04-05T08:55:14.860127Z","shell.execute_reply.started":"2024-04-05T08:55:14.852836Z","shell.execute_reply":"2024-04-05T08:55:14.859075Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms():\n  return albumentations.Compose(\n      [\n          albumentations.Resize(DIM[0],DIM[1],always_apply=True),\n          albumentations.Normalize(),\n      ToTensorV2(p=1.0)\n      ]\n  )","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.861556Z","iopub.execute_input":"2024-04-05T08:55:14.862196Z","iopub.status.idle":"2024-04-05T08:55:14.869919Z","shell.execute_reply.started":"2024-04-05T08:55:14.862159Z","shell.execute_reply":"2024-04-05T08:55:14.868940Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"eff_dataset = EfficientNetDataset(data, get_valid_transforms())","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.871207Z","iopub.execute_input":"2024-04-05T08:55:14.871995Z","iopub.status.idle":"2024-04-05T08:55:14.883523Z","shell.execute_reply.started":"2024-04-05T08:55:14.871958Z","shell.execute_reply":"2024-04-05T08:55:14.882572Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"eff_dataset_loader = torch.utils.data.DataLoader(\n  eff_dataset,\n  batch_size=8,\n  pin_memory=True,\n  drop_last=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.884759Z","iopub.execute_input":"2024-04-05T08:55:14.885133Z","iopub.status.idle":"2024-04-05T08:55:14.891190Z","shell.execute_reply.started":"2024-04-05T08:55:14.885096Z","shell.execute_reply":"2024-04-05T08:55:14.890377Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"BEST_EFF_MODEL_PATH = \"../input/efficientnet/pytorch/efficientnet/1/model_efficientnet_b3_IMG_SIZE_512_EPOCH_4_arcface.bin\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device=torch.device('cpu')\n\n# Defining Model for specific fold\neff_model = EfficientNet(**model_params)\neff_model.load_state_dict(torch.load(BEST_EFF_MODEL_PATH, map_location=device))\neff_model.to(device)\nprint(\"Loaded EfficientNet model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:14.892364Z","iopub.execute_input":"2024-04-05T08:55:14.892630Z","iopub.status.idle":"2024-04-05T08:55:15.741884Z","shell.execute_reply.started":"2024-04-05T08:55:14.892607Z","shell.execute_reply":"2024-04-05T08:55:15.740729Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Building Model Backbone for efficientnet_b3 model\nLoaded EfficientNet model\n","output_type":"stream"}]},{"cell_type":"code","source":"def eval_fn(data_loader, model,device):\n    outputs = []\n    model.eval()\n    with torch.no_grad():\n        for d in data_loader:\n            batch_size = d.size()[0]\n            image = d\n            image = image.to(device)\n            output = model(image)\n            outputs.append(output)\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:15.743537Z","iopub.execute_input":"2024-04-05T08:55:15.743909Z","iopub.status.idle":"2024-04-05T08:55:15.751012Z","shell.execute_reply.started":"2024-04-05T08:55:15.743877Z","shell.execute_reply":"2024-04-05T08:55:15.749617Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"embedded_eff = torch.cat(eval_fn(eff_dataset_loader, eff_model, device), dim=0).detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:15.752654Z","iopub.execute_input":"2024-04-05T08:55:15.753021Z","iopub.status.idle":"2024-04-05T08:55:45.401741Z","shell.execute_reply.started":"2024-04-05T08:55:15.752991Z","shell.execute_reply":"2024-04-05T08:55:45.400865Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\n\ndef get_image_neighbors(df, embeddings, KNN=50):\n\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    threshold = 4.5\n    predictions = []\n    for k in range(embeddings.shape[0]):\n        idx = np.where(distances[k,] < threshold)[0]\n        ids = indices[k,idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:45.402914Z","iopub.execute_input":"2024-04-05T08:55:45.403227Z","iopub.status.idle":"2024-04-05T08:55:45.418198Z","shell.execute_reply.started":"2024-04-05T08:55:45.403200Z","shell.execute_reply":"2024-04-05T08:55:45.417477Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df, image_predictions = get_image_neighbors(data, embedded_eff)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T08:55:45.419184Z","iopub.execute_input":"2024-04-05T08:55:45.419454Z","iopub.status.idle":"2024-04-05T08:55:47.309126Z","shell.execute_reply.started":"2024-04-05T08:55:45.419430Z","shell.execute_reply":"2024-04-05T08:55:47.307922Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_text_embeddings(data):\n    outputs = []\n    for title in data.title.values:\n        input_ids = tokenizer(title, return_tensors=\"pt\",padding='max_length',truncation=True)\n        input_ids.to(device)\n        bert_model.to(device)\n        with torch.no_grad():\n            output = bert_model(input_ids)\n        outputs.append(output)\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:06:20.066958Z","iopub.execute_input":"2024-04-05T09:06:20.067351Z","iopub.status.idle":"2024-04-05T09:06:20.073340Z","shell.execute_reply.started":"2024-04-05T09:06:20.067319Z","shell.execute_reply":"2024-04-05T09:06:20.072345Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"embedded_bert = torch.cat(get_text_embeddings(data), dim=0).detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:06:49.461594Z","iopub.execute_input":"2024-04-05T09:06:49.462372Z","iopub.status.idle":"2024-04-05T09:07:39.396222Z","shell.execute_reply.started":"2024-04-05T09:06:49.462325Z","shell.execute_reply":"2024-04-05T09:07:39.395162Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df, text_predictions = get_image_neighbors(data, embedded_eff)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T09:07:39.398183Z","iopub.execute_input":"2024-04-05T09:07:39.398582Z","iopub.status.idle":"2024-04-05T09:07:41.096857Z","shell.execute_reply.started":"2024-04-05T09:07:39.398546Z","shell.execute_reply":"2024-04-05T09:07:41.095807Z"},"trusted":true},"execution_count":43,"outputs":[]}]}